{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "from paths import *\n",
    "from helper_functions import *\n",
    "from pandas_datareader import data as pdr\n",
    "from yahoo_fin import stock_info as si\n",
    "import yfinance as yf\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] loading page [##############################] 75/75 \r"
     ]
    }
   ],
   "source": [
    "fcustom = Custom()\n",
    "cols = [0,1,2,3,4,6,43,44,45,51,52,53,63,65,68]\n",
    "\n",
    "vol1 = 'Month - Over 5%'\n",
    "filters_dict1 = {'Market Cap.': '+Micro (over $50mln)', 'Volatility': vol1}\n",
    "fcustom.set_filter(filters_dict=filters_dict1)\n",
    "df1 = fcustom.screener_view(columns=cols, sleep_sec = 1, order= 'Performance (Month)', ascend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = date.today()\n",
    "start_date = end_date - timedelta(days=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_ = datetime.today().strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = q_wl / today_ \n",
    "if not os.path.isdir(path_):\n",
    "    os.mkdir(path_)\n",
    "os.chdir(path_) \n",
    "if not os.path.isdir('temp'):\n",
    "    os.mkdir('temp')\n",
    "os.chdir('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF CSV FILES PRESENT\n",
    "\n",
    "# files = glob('*.csv')\n",
    "# ticker_df = pd.DataFrame(columns=['Ticker', '1m', '3m', '6m', 'DV', 'ADR%'])\n",
    "\n",
    "# for f in files:\n",
    "#     df = pd.read_csv(f)\n",
    "#     ticker = f.split('.')[0]\n",
    "#     for i in [6]:\n",
    "#         n_month_gain(df, i)\n",
    "#     # print(ticker)\n",
    "#     ticker_df.loc[len(ticker_df.index)] = [ticker, df['1M_low_gain'].iloc[-1], df['3M_low_gain'].iloc[-1], df['6M_low_gain'].iloc[-1],  df['DollarVolume'].iloc[-1], df['ADR%'].iloc[-1]]\n",
    "#     df.to_csv(ticker + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df1['Ticker']\n",
    "request_times = []\n",
    "errors = 0\n",
    "ticker_df = pd.DataFrame(columns=['Ticker', '1m', '3m', '6m', 'DV', 'ADR%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Download historical data as CSV for each stock (makes the process faster)\n",
    "        while len(request_times) >= 2000 and (time.time() - request_times[-2000]) < 3600:\n",
    "            time.sleep(1)\n",
    "        \n",
    "        df = yf.download(ticker, period='6mo')\n",
    "        request_times.append(time.time())\n",
    "        \n",
    "        #pre-processing\n",
    "        df.rename(columns=str.lower, inplace=True)\n",
    "        df.drop('close', axis=1, inplace=True)\n",
    "        df.rename(columns={'adj close': 'close'}, inplace=True)\n",
    "        adr(df)\n",
    "        df['DollarVolume'] = df['close'] * df['volume']\n",
    "        \n",
    "        #n-month gains\n",
    "        for i in [1,3,6]:\n",
    "            n_month_gain(df, i)\n",
    "        # print(ticker_df)\n",
    "        ticker_df.loc[len(ticker_df.index)] = [ticker, df['1M_low_gain'].iloc[-1], df['3M_low_gain'].iloc[-1], df['6M_low_gain'].iloc[-1],  df['DollarVolume'].iloc[-1], df['ADR%'].iloc[-1]]\n",
    "        print(ticker, df.shape)\n",
    "        df.to_csv(ticker + '.csv')\n",
    "    except:\n",
    "        print('Error for ticker: ', ticker)\n",
    "        errors += 1\n",
    "print('Time taken: {}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df = pd.merge(ticker_df, df1, on='Ticker')\n",
    "ticker_df = ticker_df[['Ticker', '1m','3m','6m','DV', 'ADR%', 'Company', 'Sector', 'Industry', 'Market Cap', 'Price', 'Earnings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "mil = 10 ** 6\n",
    "adr_filter = 5.0\n",
    "dv_filter = 1 * mil\n",
    "limit = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTER\n",
    "ticker_df_filt = ticker_df[(ticker_df['ADR%'] >= adr_filter) & (ticker_df['DV'] >= dv_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANK\n",
    "ticker_df_filt['1m_Rating'] = ticker_df_filt['1m'].rank(ascending=False)\n",
    "ticker_df_filt['3m_Rating'] = ticker_df_filt['3m'].rank(ascending=False)\n",
    "ticker_df_filt['6m_Rating'] = ticker_df_filt['6m'].rank(ascending=False)\n",
    "\n",
    "ticker_df_1m = ticker_df_filt[ticker_df_filt['1m_Rating'] <= limit]\n",
    "ticker_df_3m = ticker_df_filt[ticker_df_filt['3m_Rating'] <= limit]\n",
    "ticker_df_6m = ticker_df_filt[ticker_df_filt['6m_Rating'] <= limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df_final = pd.concat([ticker_df_1m, ticker_df_3m, ticker_df_6m], axis=0)\n",
    "ticker_df_final = ticker_df_final.drop_duplicates(subset=['Ticker'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(q_wl / today_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230209_1_M_Q_US.txt\n",
      "20230209_3_M_Q_US.txt\n",
      "20230209_6_M_Q_US.txt\n",
      "20230209_Q_US.txt\n"
     ]
    }
   ],
   "source": [
    "s1 = set(ticker_df_1m['Ticker'])\n",
    "set_to_tv(s1, datetime.today().strftime('%Y%m%d') + '_1_M_Q_US.txt')\n",
    "s3 = set(ticker_df_3m['Ticker'])\n",
    "set_to_tv(s3, datetime.today().strftime('%Y%m%d') + '_3_M_Q_US.txt')\n",
    "s6 = set(ticker_df_6m['Ticker'])\n",
    "set_to_tv(s6, datetime.today().strftime('%Y%m%d') + '_6_M_Q_US.txt')\n",
    "\n",
    "s = set(ticker_df_final['Ticker'])\n",
    "set_to_tv(s, datetime.today().strftime('%Y%m%d') + '_Q_US.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = fcustom.get_filter_options('Industry')\n",
    "# sector = set(df1['Sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df_final.to_csv('INFO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yash/Desktop/Trading/Q/watchlists/2023/02/09'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('temp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
